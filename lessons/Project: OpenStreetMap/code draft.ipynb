{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an excerpt of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See create_sample.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "Count element types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from collections import defaultdict\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "\n",
    "def count_tags(filename):\n",
    "    counter = defaultdict(int)\n",
    "    with open(filename) as f:\n",
    "        for event, element in ET.iterparse(f):\n",
    "            counter[element.tag] += 1\n",
    "    return counter\n",
    "    \n",
    "\n",
    "def test():\n",
    "    tags = count_tags('dresden_germany.sample_k=100.osm')\n",
    "    pprint.pprint(tags)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse node and ways with their tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "filename = 'dresden_germany.sample_k=10.osm'\n",
    "\n",
    "TOP_LEVEL_TAGS = [\"way\", \"node\"]\n",
    "CREATED = [\"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "# Count tag keys per parent element type (e.g. \"node\", \"way\", ...).\n",
    "tag_keys = defaultdict(Counter)\n",
    "element_counter = Counter()\n",
    "\n",
    "\n",
    "def count_tag_key(tag, parent):\n",
    "    k = tag.attrib[\"k\"]\n",
    "    tag_keys[parent][k] += 1\n",
    "\n",
    "    \n",
    "def parse_address(element):\n",
    "    address = {}\n",
    "    for subtag in element.iter(\"tag\"):\n",
    "        k = subtag.attrib[\"k\"]\n",
    "        v = subtag.attrib[\"v\"]\n",
    "        if problemchars.match(k):\n",
    "            print(k)\n",
    "            continue\n",
    "        elif k.count(\":\") > 1:\n",
    "            continue\n",
    "        elif k.startswith(\"addr:\"):\n",
    "            key = k.split(\":\")[1]\n",
    "            address[key] = v\n",
    "    return address\n",
    "        \n",
    "# Maps each type of special information to a list of fields which we care for.\n",
    "SPECIAL_TYPES = {\"shop\": [\"name\", \"wheelchair\", \"opening_hours\"]}\n",
    "\n",
    "    \n",
    "def parse_specials(element):\n",
    "    content = {}\n",
    "    type_ = None\n",
    "    for subtag in element.iter(\"tag\"):\n",
    "        k = subtag.attrib[\"k\"]\n",
    "        v = subtag.attrib[\"v\"]\n",
    "        if k in SPECIAL_TYPES:\n",
    "            type_ = k\n",
    "        else:\n",
    "            content[k] = v\n",
    "    content = {k: v for k, v in content.items() \n",
    "               if type_ in SPECIAL_TYPES and k in SPECIAL_TYPES[type_]}       \n",
    "    \n",
    "    return type_, content\n",
    "    \n",
    "    \n",
    "def parse_node(element):\n",
    "    node = {}\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        count_tag_key(tag, \"node\")\n",
    "    element_counter[\"node\"] += 1\n",
    "    address = parse_address(element)\n",
    "    if address:\n",
    "        node[\"address\"] = address\n",
    "    special_type, special_content = parse_specials(element)\n",
    "    if special_type:\n",
    "        node[special_type] = special_content\n",
    "    return node\n",
    "\n",
    "\n",
    "def parse_way_nodes(element):\n",
    "    nodes = []\n",
    "    for node in element.iter(\"nd\"):\n",
    "        nodes.append(node.attrib[\"ref\"])\n",
    "    return nodes     \n",
    "\n",
    "    \n",
    "def parse_way(element):\n",
    "    way = {}\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        count_tag_key(tag, \"way\")\n",
    "    element_counter[\"way\"] += 1\n",
    "    way_nodes = parse_way_nodes(element)\n",
    "    if way_nodes:\n",
    "        way[\"nodes\"] = way_nodes    \n",
    "    return way\n",
    "\n",
    "\n",
    "def parse_tags(element):\n",
    "    tags = {}\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        print(\"tag\", tag.attrib)\n",
    "        k, v = tag.attrib[\"k\"], tag.attrib[\"v\"]\n",
    "        if k.startswith(\"addr:\"):\n",
    "            continue  # skip address tags, will be parsed otherwise\n",
    "        tags[k] = v\n",
    "    return tags\n",
    "\n",
    "    \n",
    "def parse_element(element):\n",
    "    node = None\n",
    "    if element.tag == \"way\":\n",
    "        node = parse_way(element)\n",
    "    elif element.tag == \"node\":\n",
    "        node = parse_node(element)\n",
    "    node[\"created\"] = {}\n",
    "    node[\"type\"] = element.tag\n",
    "    lat = lon = None\n",
    "    for k, v in element.attrib.items():\n",
    "        if k in CREATED:\n",
    "            node[\"created\"][k] = v\n",
    "        elif k == \"lat\":\n",
    "            lat = float(v)\n",
    "        elif k == \"lon\":\n",
    "            lon = float(v)\n",
    "        else:\n",
    "            node[k] = v\n",
    "    if lat and lon:\n",
    "        node[\"pos\"] = [lat, lon]\n",
    "        \n",
    "    # TODO(Jonas): Disable generic parsing of all tags later on.    \n",
    "    tags = parse_tags(element)\n",
    "    if tags:\n",
    "        node[\"tags\"] = tags\n",
    "\n",
    "    return node\n",
    "\n",
    "    \n",
    "filename_out = \"{0}.json\".format(filename)\n",
    "with open(filename) as f:\n",
    "    with codecs.open(filename_out, \"w\") as fout:\n",
    "        for event, element in ET.iterparse(f, events=[\"end\"]):\n",
    "            if element.tag in TOP_LEVEL_TAGS:\n",
    "                #print(element)\n",
    "                el = parse_element(element)\n",
    "                #fout.write(json.dumps(el, indent=2) + \"\\n\")\n",
    "                fout.write(json.dumps(el) + \"\\n\")\n",
    "            \n",
    "        \n",
    "pprint.pprint(tag_keys)\n",
    "#pprint.pprint(element_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "  * Parse the data using cElementTree.\n",
    "  * Create some statistics while parsing, document them. Note: Maybe this should be done in the end, using queries against MongoDB.\n",
    "  * _Restrict the data to streets (ways with a tag with k=highway) [optional, I guess]_\n",
    "  * Do a little data cleaning:\n",
    "    * Parse street name tags and unify abbreviations (later include the types into the statistics)\n",
    "  * Create JSON output from the data\n",
    "  * Import it into MongoDB\n",
    "  * Run statistics queries against it, audit, find and document problems, iterate from the beginning\n",
    "    * Number of ways, nodes\n",
    "    * Longest way (most way_nodes)\n",
    "    * Top 10 tags\n",
    "    * Top 3 contributing users\n",
    "    * Most frequent shop name\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encountered problems (and solution)\n",
    "\n",
    "  * Many elements are duplicated -- by my mistake or due to errorneous data?\n",
    "    * It was my mistake, caused by reading \"end\" and \"start\" events from iterparse.\n",
    "  * mongoimport reads one element per line, not prettyfied JSON\n",
    "  * fix UTF-8 encoding / decoding\n",
    "  * What is the most frequent shop? Some nodes have a shop field, but no name. Find out what is going on and if these can be safely ignored.\n",
    " \n",
    "## Audited data\n",
    "\n",
    "  * shops: parse name, wheelchair accessibility and opening hours\n",
    "  * places: detect suburbs etc. (todo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
