{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Data Extraction\n",
    "\n",
    "## Exercise 1: Python's xlrd and csvb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Your task is to process the supplied file and use the csv module to extract data from it.\n",
    "The data comes from NREL (National Renewable Energy Laboratory) website. Each file\n",
    "contains information from one meteorological station, in particular - about amount of\n",
    "solar and wind energy for each hour of day.\n",
    "\n",
    "Note that the first line of the datafile is neither data entry, nor header. It is a line\n",
    "describing the data source. You should extract the name of the station from it.\n",
    "\n",
    "The data should be returned as a list of lists (not dictionaries).\n",
    "You can use the csv modules \"reader\" method to get data in such format.\n",
    "Another useful method is next() - to get the next line from the iterator.\n",
    "You should only change the parse_file function.\n",
    "\"\"\"\n",
    "import csv\n",
    "import os\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"745090.csv\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    name = \"\"\n",
    "    data = []\n",
    "    with open(datafile,'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        # Read the station name.\n",
    "        name = reader.next()[1]\n",
    "        \n",
    "        # Skip the header line.\n",
    "        reader.next()\n",
    "        \n",
    "        # Convert the remaining entries to a list of lists.\n",
    "        data = list(reader)\n",
    "        \n",
    "    # Do not change the line below\n",
    "    return (name, data)\n",
    "\n",
    "\n",
    "def test():\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    name, data = parse_file(datafile)\n",
    "\n",
    "    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\n",
    "    assert data[0][1] == \"01:00\"\n",
    "    assert data[2][0] == \"01/01/2005\"\n",
    "    assert data[2][5] == \"2\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Python's xlrd and csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Find the time and value of max load for each of the regions\n",
    "COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character | as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file.\n",
    "'''\n",
    "\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\"\n",
    "\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    data = []\n",
    "    data.append([\"Station\", \"Year\", \"Month\", \"Day\", \"Hour\", \"Max Load\"])\n",
    "    timestamps = sheet.col_values(0)\n",
    "    # Ignore the first and last column (timestamp and \"ERCOT\" whatever).\n",
    "    for column_index in range(1, sheet.ncols - 1):\n",
    "        station = sheet.cell_value(0, column_index)\n",
    "        rows = sheet.col_values(column_index, 1)\n",
    "        value = max(rows)\n",
    "        index = rows.index(value) + 1  # we are working on the slice col[x][1:]\n",
    "        time = xlrd.xldate_as_tuple(timestamps[index], 0)\n",
    "        data.append([station, time[0], time[1], time[2], time[3], value])\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_file(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        writer = csv.writer(f, delimiter=\"|\")\n",
    "        writer.writerows(data)\n",
    "\n",
    "    \n",
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "    save_file(data, outfile)\n",
    "\n",
    "    number_of_rows = 0\n",
    "    stations = []\n",
    "\n",
    "    ans = {'FAR_WEST': {'Max Load': '2281.2722140000024',\n",
    "                        'Year': '2013',\n",
    "                        'Month': '6',\n",
    "                        'Day': '26',\n",
    "                        'Hour': '17'}}\n",
    "    correct_stations = ['COAST', 'EAST', 'FAR_WEST', 'NORTH',\n",
    "                        'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n",
    "    fields = ['Year', 'Month', 'Day', 'Hour', 'Max Load']\n",
    "\n",
    "    with open(outfile) as of:\n",
    "        csvfile = csv.DictReader(of, delimiter=\"|\")\n",
    "        for line in csvfile:\n",
    "            station = line['Station']\n",
    "            if station == 'FAR_WEST':\n",
    "                for field in fields:\n",
    "                    # Check if 'Max Load' is within .1 of answer\n",
    "                    if field == 'Max Load':\n",
    "                        max_answer = round(float(ans[station][field]), 1)\n",
    "                        max_line = round(float(line[field]), 1)\n",
    "                        assert max_answer == max_line\n",
    "\n",
    "                    # Otherwise check for equality\n",
    "                    else:\n",
    "                        assert ans[station][field] == line[field]\n",
    "\n",
    "            number_of_rows += 1\n",
    "            stations.append(station)\n",
    "\n",
    "        # Output should be 8 lines not including header\n",
    "        assert number_of_rows == 8\n",
    "\n",
    "        # Check Station Names\n",
    "        assert set(stations) == set(correct_stations)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Python's json\n",
    "\n",
    "The exercise works on the NYT data on popular articles, see [API](http://developer.nytimes.com/docs/most_popular_api/). Find the master solution below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def article_overview(kind, period):\n",
    "    data = get_from_file(kind, period)\n",
    "    titles = []\n",
    "    urls =[]\n",
    "\n",
    "    for article in data:\n",
    "        section = article[\"section\"]\n",
    "        title = article[\"title\"]\n",
    "        titles.append({section: title})\n",
    "        if \"media\" in article:\n",
    "            for m in article[\"media\"]:\n",
    "                for mm in m[\"media-metadata\"]:\n",
    "                    if mm[\"format\"] == \"Standard Thumbnail\":\n",
    "                        urls.append(mm[\"url\"])\n",
    "    return (titles, urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
